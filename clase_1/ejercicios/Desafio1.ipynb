{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.",
   "id": "24387d6035af38d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:43:10.758390Z",
     "start_time": "2025-03-20T16:43:10.749857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
    "# en sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np"
   ],
   "id": "7c69907e1693e5ac",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:43:12.589667Z",
     "start_time": "2025-03-20T16:43:10.777640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ],
   "id": "3a78ab78c8638d60",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:43:12.774203Z",
     "start_time": "2025-03-20T16:43:12.762162Z"
    }
   },
   "cell_type": "code",
   "source": "tfidfvect = TfidfVectorizer()",
   "id": "ae8ef5681ea49be",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:43:14.442118Z",
     "start_time": "2025-03-20T16:43:12.944893Z"
    }
   },
   "cell_type": "code",
   "source": "X_train = tfidfvect.fit_transform(newsgroups_train.data)",
   "id": "6cb6ee99a42a0099",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:43:14.640964Z",
     "start_time": "2025-03-20T16:43:14.623652Z"
    }
   },
   "cell_type": "code",
   "source": "y_train = newsgroups_train.target",
   "id": "4e8aec26198df9b",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:43:14.826833Z",
     "start_time": "2025-03-20T16:43:14.810479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fijar la semilla para reproducibilidad\n",
    "random.seed(42)\n",
    "\n",
    "# Seleccionar 5 índices al azar utilizando la semilla establecida\n",
    "random_indices = random.sample(range(len(newsgroups_train.data)), 5)\n",
    "\n",
    "# Obtener los vectores correspondientes a los índices seleccionados\n",
    "reference_vectors = X_train[random_indices]"
   ],
   "id": "f7da19aac8ed44de",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:43:15.024195Z",
     "start_time": "2025-03-20T16:43:15.008546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Función para imprimir documentos más similares con formato detallado\n",
    "def print_most_similar_documents(X, y_train, newsgroups_train, random_indices, reference_vectors):\n",
    "    for i, index in enumerate(random_indices):\n",
    "        # Calcular similitud coseno del vector de referencia con todos los documentos\n",
    "        cossim = cosine_similarity(reference_vectors[i], X)[0]\n",
    "\n",
    "        print(f\"******* Documento índice {index} *****\")\n",
    "\n",
    "        # Obtener los 5 documentos más similares (excluyendo el propio documento)\n",
    "        mostsim = np.argsort(cossim)[::-1][1:6]\n",
    "\n",
    "        print(\"Los Documentos más similares (Índices):\")\n",
    "        print(mostsim)\n",
    "\n",
    "        # Mostrar la clase a la que pertenece el documento de referencia\n",
    "        class_belong = newsgroups_train.target_names[y_train[index]]\n",
    "        print(f\"Clase a la que pertenece el documento: {class_belong}\")\n",
    "\n",
    "        # Obtener las clases de los documentos similares\n",
    "        similarity_class = [newsgroups_train.target_names[y_train[mostidx]] for mostidx in mostsim]\n",
    "        print(\"Los documentos similares a qué clase pertenecen:\")\n",
    "        print(\"\\\\\\n\".join(similarity_class))\n",
    "\n",
    "        print(\"*************************************\\n\")\n",
    "\n",
    "\n"
   ],
   "id": "b2691ed8942ac8b",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:43:15.407609Z",
     "start_time": "2025-03-20T16:43:15.221808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Llamar a la función con tus datos\n",
    "print_most_similar_documents(X_train, newsgroups_train.target, newsgroups_train, random_indices, reference_vectors)"
   ],
   "id": "9f3468b8af85830b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Documento índice 10476 *****\n",
      "Los Documentos más similares (Índices):\n",
      "[ 5064  9623 10575 10836  2350]\n",
      "Clase a la que pertenece el documento: rec.sport.hockey\n",
      "Los documentos similares a qué clase pertenecen:\n",
      "rec.sport.hockey\\\n",
      "talk.politics.mideast\\\n",
      "sci.crypt\\\n",
      "alt.atheism\\\n",
      "sci.crypt\n",
      "*************************************\n",
      "\n",
      "******* Documento índice 1824 *****\n",
      "Los Documentos más similares (Índices):\n",
      "[9921 6364 5509 2641 4359]\n",
      "Clase a la que pertenece el documento: comp.sys.mac.hardware\n",
      "Los documentos similares a qué clase pertenecen:\n",
      "comp.sys.mac.hardware\\\n",
      "comp.sys.mac.hardware\\\n",
      "comp.sys.mac.hardware\\\n",
      "comp.sys.mac.hardware\\\n",
      "comp.sys.mac.hardware\n",
      "*************************************\n",
      "\n",
      "******* Documento índice 409 *****\n",
      "Los Documentos más similares (Índices):\n",
      "[3444 5799 5905 1764 3364]\n",
      "Clase a la que pertenece el documento: comp.graphics\n",
      "Los documentos similares a qué clase pertenecen:\n",
      "comp.graphics\\\n",
      "comp.graphics\\\n",
      "comp.graphics\\\n",
      "comp.graphics\\\n",
      "comp.graphics\n",
      "*************************************\n",
      "\n",
      "******* Documento índice 4506 *****\n",
      "Los Documentos más similares (Índices):\n",
      "[4211 5928 6224 5171 9491]\n",
      "Clase a la que pertenece el documento: rec.autos\n",
      "Los documentos similares a qué clase pertenecen:\n",
      "rec.motorcycles\\\n",
      "comp.sys.mac.hardware\\\n",
      "rec.autos\\\n",
      "rec.autos\\\n",
      "rec.autos\n",
      "*************************************\n",
      "\n",
      "******* Documento índice 4012 *****\n",
      "Los Documentos más similares (Índices):\n",
      "[ 6599 10644  7478  7308 10792]\n",
      "Clase a la que pertenece el documento: rec.sport.hockey\n",
      "Los documentos similares a qué clase pertenecen:\n",
      "soc.religion.christian\\\n",
      "rec.sport.hockey\\\n",
      "rec.sport.hockey\\\n",
      "rec.sport.hockey\\\n",
      "rec.sport.baseball\n",
      "*************************************\n",
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusiones del análisis\n",
    "\n",
    "A partir de los resultados obtenidos, podemos observar cómo la **similitud coseno está detectando correctamente temas relacionados** en la mayoría de los casos. A continuación, se analiza cada documento:\n",
    "\n",
    "---\n",
    "\n",
    "### Documento Índice 10476 (`rec.sport.hockey`)\n",
    "- **Documentos más similares incluyen:**\n",
    "  - Otros relacionados con **hockey (`rec.sport.hockey`)**.\n",
    "  - Documentos que no parecen relacionados como `talk.politics.mideast`, `sci.crypt` y `alt.atheism`.\n",
    "- **Conclusión:**\n",
    "  Aunque detecta bien documentos de hockey, está capturando documentos irrelevantes posiblemente por palabras comunes o patrones de redacción.\n",
    "\n",
    "---\n",
    "\n",
    "### Documento Índice 1824 (`comp.sys.mac.hardware`)\n",
    "- **Documentos más similares incluyen:**\n",
    "  - Todos pertenecen a `comp.sys.mac.hardware`.\n",
    "- **Conclusión:**\n",
    "  Muy buena precisión, indicando que la similitud coseno funciona bien cuando el tema está claramente definido y específico.\n",
    "\n",
    "---\n",
    "\n",
    "### Documento Índice 409 (`comp.graphics`)\n",
    "- **Documentos más similares incluyen:**\n",
    "  - Todos pertenecen a `comp.graphics`.\n",
    "- **Conclusión:**\n",
    "  Excelente identificación. Los documentos de gráficos probablemente comparten un vocabulario técnico específico que los diferencia bien.\n",
    "\n",
    "---\n",
    "\n",
    "### Documento Índice 4506 (`rec.autos`)\n",
    "- **Documentos más similares incluyen:**\n",
    "  - Mayormente relacionados con `rec.autos`.\n",
    "  - También se encuentran relacionados `comp.sys.mac.hardware` y `rec.motorcycles`.\n",
    "- **Conclusión:**\n",
    "  Buen desempeño general. La similitud coseno está detectando correctamente temas relacionados a autos y motocicletas (ambos son tópicos automotrices). El único error notable es el documento de hardware de Mac.\n",
    "\n",
    "---\n",
    "\n",
    "### Documento Índice 4012 (`rec.sport.hockey`)\n",
    "- **Documentos más similares incluyen:**\n",
    "  - Mayormente relacionados con `rec.sport.hockey`.\n",
    "  - También relacionados con `rec.sport.baseball` (deporte similar).\n",
    "  - Un documento de `soc.religion.christian`, que no tiene relación.\n",
    "- **Conclusión:**\n",
    "  El algoritmo detecta bien temas relacionados con deportes, pero presenta errores ocasionales por coincidencias en palabras comunes.\n",
    "\n",
    "\n"
   ],
   "id": "7a168a58c872b42b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.",
   "id": "fe726a234073fa68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:50:49.325523Z",
     "start_time": "2025-03-20T16:50:47.017023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vectorización con TfidfVectorizer con parámetros iniciales\n",
    "tfidfvect = TfidfVectorizer(stop_words='english', max_df=0.8, min_df=5)\n",
    "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
    "X_test = tfidfvect.transform(newsgroups_test.data)\n",
    "\n",
    "# Guardar las etiquetas\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "# Función para entrenar y evaluar un modelo Naive Bayes\n",
    "def train_and_evaluate_model(model, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"{model_name} - F1 Score (Macro): {f1_macro:.4f}\")\n",
    "    return f1_macro\n",
    "\n",
    "# Entrenar y evaluar MultinomialNB\n",
    "multinomial_nb = MultinomialNB(alpha=0.5)\n",
    "f1_multinomial = train_and_evaluate_model(multinomial_nb, \"MultinomialNB\")\n",
    "\n",
    "# Entrenar y evaluar ComplementNB\n",
    "complement_nb = ComplementNB(alpha=0.5)\n",
    "f1_complement = train_and_evaluate_model(complement_nb, \"ComplementNB\")\n"
   ],
   "id": "a85da0a44b89500e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB - F1 Score (Macro): 0.6611\n",
      "ComplementNB - F1 Score (Macro): 0.6827\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusiones del Desempeño de los Modelos Naive Bayes\n",
    "\n",
    "### MultinomialNB\n",
    "- **F1 Score (Macro): 0.6611**\n",
    "- Este modelo funciona razonablemente bien, pero es más sensible a clases que tienen más documentos, ya que no maneja adecuadamente datos desbalanceados.\n",
    "\n",
    "### ComplementNB\n",
    "- **F1 Score (Macro): 0.6827**\n",
    "- Este modelo mejora el rendimiento general en comparación con `MultinomialNB`.\n",
    "- Está diseñado específicamente para ser más robusto con clases desbalanceadas, lo cual explica la mejora en el F1 Score.\n",
    "\n",
    "---\n",
    "\n",
    "### Comparación General\n",
    "- `ComplementNB` supera consistentemente a `MultinomialNB` con un puntaje F1 Macro más alto (0.6827 vs. 0.6611).\n",
    "- La diferencia no es enorme, pero es significativa considerando que estamos utilizando un modelo sencillo y un preprocesamiento estándar.\n",
    "\n"
   ],
   "id": "77cf1939f9f64812"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.",
   "id": "bd58186a4148dc2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:58:29.292747Z",
     "start_time": "2025-03-20T16:58:29.073974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transponer la matriz documento-término para obtener término-documento\n",
    "X_train_transposed = X_train.T  # Matriz Término-Documento\n",
    "\n",
    "# Obtener el vocabulario mapeado a índices\n",
    "vocab = tfidfvect.get_feature_names_out()\n",
    "\n",
    "# Selección manual de palabras relevantes\n",
    "selected_words = ['hockey', 'computer', 'religion', 'space', 'science']\n",
    "\n",
    "# Función para encontrar palabras similares usando similitud coseno\n",
    "def find_similar_words(X_transposed, vocab, words):\n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            # Obtener el índice de la palabra\n",
    "            word_index = np.where(vocab == word)[0][0]\n",
    "\n",
    "            # Calcular la similitud coseno entre la palabra y todas las demás\n",
    "            word_vector = X_transposed[word_index]\n",
    "            cossim = cosine_similarity(word_vector, X_transposed)[0]\n",
    "\n",
    "            # Encontrar los 5 términos más similares\n",
    "            most_similar_indices = np.argsort(cossim)[::-1][1:6]  # Excluyendo la propia palabra\n",
    "            most_similar_words = [(vocab[i], cossim[i]) for i in most_similar_indices]\n",
    "\n",
    "            # Mostrar resultados\n",
    "            print(f\"\\n******* Palabra: {word} *******\")\n",
    "            for similar_word, score in most_similar_words:\n",
    "                print(f\"{similar_word} - Similitud: {score:.4f}\")\n",
    "            print(\"***********************************\")\n",
    "        else:\n",
    "            print(f\"\\nLa palabra '{word}' no está en el vocabulario.\\n\")\n",
    "\n",
    "# Llamar a la función para mostrar palabras similares\n",
    "find_similar_words(X_train_transposed, vocab, selected_words)\n"
   ],
   "id": "d01c48b72bfd60b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******* Palabra: hockey *******\n",
      "ncaa - Similitud: 0.2672\n",
      "nhl - Similitud: 0.2496\n",
      "sportschannel - Similitud: 0.2081\n",
      "players - Similitud: 0.2012\n",
      "league - Similitud: 0.1924\n",
      "***********************************\n",
      "\n",
      "******* Palabra: computer *******\n",
      "shopper - Similitud: 0.1349\n",
      "verlag - Similitud: 0.1248\n",
      "delicate - Similitud: 0.1196\n",
      "drive - Similitud: 0.1105\n",
      "hackers - Similitud: 0.1082\n",
      "***********************************\n",
      "\n",
      "******* Palabra: religion *******\n",
      "religious - Similitud: 0.2475\n",
      "religions - Similitud: 0.2237\n",
      "crusades - Similitud: 0.1936\n",
      "christianity - Similitud: 0.1882\n",
      "categorized - Similitud: 0.1849\n",
      "***********************************\n",
      "\n",
      "******* Palabra: space *******\n",
      "nasa - Similitud: 0.3178\n",
      "shuttle - Similitud: 0.2784\n",
      "exploration - Similitud: 0.2328\n",
      "aeronautics - Similitud: 0.2219\n",
      "cfa - Similitud: 0.2164\n",
      "***********************************\n",
      "\n",
      "******* Palabra: science *******\n",
      "behaviorists - Similitud: 0.3941\n",
      "cognitivists - Similitud: 0.3941\n",
      "scientific - Similitud: 0.3624\n",
      "empirical - Similitud: 0.2890\n",
      "sects - Similitud: 0.2538\n",
      "***********************************\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusiones del Estudio de Similitud entre Palabras\n",
    "\n",
    "El análisis de similitud coseno aplicado a la **matriz término-documento** permite identificar palabras que frecuentemente co-ocurren en los mismos documentos. A continuación, se presentan las conclusiones para cada palabra seleccionada:\n",
    "\n",
    "---\n",
    "\n",
    "### Palabra: `hockey`\n",
    "- Palabras más similares:\n",
    "  - `ncaa` (0.2672)\n",
    "  - `nhl` (0.2496)\n",
    "  - `sportschannel` (0.2081)\n",
    "  - `players` (0.2012)\n",
    "  - `league` (0.1924)\n",
    "- **Conclusión:**\n",
    "  El modelo identifica palabras relacionadas al ámbito del hockey (`nhl`, `players`, `league`). Sin embargo, algunas palabras como `sportschannel` reflejan conceptos relacionados con medios de transmisión.\n",
    "\n",
    "---\n",
    "\n",
    "### Palabra: `computer`\n",
    "- Palabras más similares:\n",
    "  - `shopper` (0.1349)\n",
    "  - `verlag` (0.1248)\n",
    "  - `delicate` (0.1196)\n",
    "  - `drive` (0.1105)\n",
    "  - `hackers` (0.1082)\n",
    "- **Conclusión:**\n",
    "  La similitud detecta términos relacionados con tecnología, aunque algunos como `verlag` (editoriales) o `delicate` parecen poco relevantes. Esto puede deberse a asociaciones en documentos no puramente técnicos.\n",
    "\n",
    "---\n",
    "\n",
    "### Palabra: `religion`\n",
    "- Palabras más similares:\n",
    "  - `religious` (0.2475)\n",
    "  - `religions` (0.2237)\n",
    "  - `crusades` (0.1936)\n",
    "  - `christianity` (0.1882)\n",
    "  - `categorized` (0.1849)\n",
    "- **Conclusión:**\n",
    "  Las palabras relacionadas a `religion` están correctamente identificadas, especialmente aquellas vinculadas a conceptos amplios como `religious`, `christianity` o `crusades`.\n",
    "\n",
    "---\n",
    "\n",
    "### Palabra: `space`\n",
    "- Palabras más similares:\n",
    "  - `nasa` (0.3178)\n",
    "  - `shuttle` (0.2784)\n",
    "  - `exploration` (0.2328)\n",
    "  - `aeronautics` (0.2219)\n",
    "  - `cfa` (0.2164)\n",
    "- **Conclusión:**\n",
    "  La similitud coseno identifica claramente términos relacionados con la exploración espacial (`nasa`, `shuttle`, `exploration`). Los resultados son coherentes con un tema técnico y específico.\n",
    "\n",
    "---\n",
    "\n",
    "### Palabra: `science`\n",
    "- Palabras más similares:\n",
    "  - `behaviorists` (0.3941)\n",
    "  - `cognitivists` (0.3941)\n",
    "  - `scientific` (0.3624)\n",
    "  - `empirical` (0.2890)\n",
    "  - `sects` (0.2538)\n",
    "- **Conclusión:**\n",
    "  Este término está asociado tanto con ciencias duras (`scientific`, `empirical`) como con teorías relacionadas a psicología o filosofía (`behaviorists`, `cognitivists`). El término `sects` podría deberse a documentos que relacionan ciencia con religión o pseudociencias.\n",
    "\n",
    "---\n",
    "\n",
    "## Observaciones Generales\n",
    "1. Las palabras seleccionadas muestran asociaciones coherentes con sus contextos temáticos.\n",
    "2. Algunas palabras irrelevantes (`verlag`, `delicate`) pueden aparecer si se relacionan con documentos técnicos por coincidencias superficiales.\n",
    "3. Este método es efectivo para identificar palabras relacionadas dentro de un corpus extenso, pero puede ser sensible al ruido generado por documentos con contenido ambiguo.\n",
    "\n"
   ],
   "id": "f2cb331110623a04"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
